# Helm chart values for deploying Cycloid and related components.

nameOverride: ""
fullnameOverride: ""

# Common labels to add to all Kubernetes objects created by this chart.
commonLabels: {}

# Common annotations to add to all Kubernetes objects created by this chart.
commonAnnotations: {}

# Cycloid image registry configuration.
# To access Cycloid docker images, a docker-registry token that expires is used.
# By default, the cronjob (via the renewToken parameter) is enabled to renew the docker-registry token
# that allow pulling images on the Cycloid image registry
cycloidImagesRegistry:
  # Enable a cronjob to renew the docker-registry token periodically.
  # not needed with scaleway login
  renewToken: false
  # Kubernetes secret containing credentials for accessing the image registry.
  secretCredentialName: cycloid-aws-creds
  # URL of the Docker image repository.
  repositoryUrl: 661913936052.dkr.ecr.eu-west-1.amazonaws.com
  # AWS region of the Docker image repository.
  repositoryRegion: eu-west-1
  # Cron schedule for renewing the token.
  refreshEvery: "0 */6 * * *"
  # Docker image used by the cronjob to renew the token.
  image: alpine/k8s:1.29.8

# Image pull secret used for authenticating with the Docker registry.
# The default value matches the secret created during the documentation installation steps
# which provide access to the scaleway Cycloid docker images.
# Note! In case of use of the AWS ECR instead change to cycloid-ecr
imagePullSecrets:
  - name: scw-registry-secret

# Set to true if deploying on OpenShift.
openshift: false

#
# Cycloid Console frontend
#
frontend:
  # Enable the Cycloid Console frontend service.
  enabled: true

  # Override the default name for the frontend service.
  nameOverride: "frontend"
  # Override the full name for the frontend service.
  fullnameOverride: ""

  # External URL for accessing the Cycloid Console frontend.
  # If you change this value, update the ingress declaration below too.
  url: "http://console.cycloid.local"

  # Number of replicas for the frontend service.
  replicaCount: 1

  image:
    # If using AWS replace by 661913936052.dkr.ecr.eu-west-1.amazonaws.com/youdeploy-frontend
    repository: rg.fr-par.scw.cloud/cycloidio/cycloid-frontend
    pullPolicy: Always
    # Tag of the Docker image to use.
    tag: "latest-public"
    # Container port to expose for the frontend service.
    containerPort: 80

  # List of additional environment variables to set for the frontend container.
  extraEnvVars:
    {}
    # MYENVVAR: VALUE

  # List of additional environment variables to set from existing Kubernetes Secrets.
  extraSecretEnvVars:
    []
    # - envName: MYENVVAR
    #   secretName: secret_name
    #   secretKey: SECRET_KEY

  # List of additional environment variables to set from existing ConfigMaps.
  extraConfigMapEnvVars:
    []
    # - envName: MYENVVAR
    #   configMapName: configmap_name
    #   configMapKey: CONFIGMAP_KEY

  # Name of an existing ConfigMap containing additional environment variables.
  extraFullConfigMapEnvVars: ""

  # Name of an existing Secret containing additional environment variables.
  extraFullSecretEnvVars: ""

  serviceAccount:
    # Specify whether a service account should be created for the frontend.
    create: true
    # Annotations to add to the service account.
    annotations: {}
    # Name of the service account to use. If not set, a name is generated.
    name: ""

  podAnnotations: {}

  podSecurityContext:
    # Enable security context for frontend pods.
    enabled: false
    # fsGroup: 2000

  securityContext:
    # Enable security context for frontend containers.
    enabled: false
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  ingress:
    # Enable ingress for the frontend service.
    enabled: true
    # Class name for the ingress controller. Example "nginx"
    className: ""
    annotations:
      {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: console.cycloid.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    # Certificate configuration for the ingress.
    tls: []
    #  - secretName: cycloid-local-tls
    #    hosts:
    #      - console.cycloid.local

  resources:
    {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    # Enable or disable horizontal pod autoscaling for the frontend.
    enabled: false
    # Minimum number of replicas.
    minReplicas: 1
    # Maximum number of replicas.
    maxReplicas: 100
    # Target CPU utilization percentage for scaling.
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  # Affinity settings for scheduling frontend pods on specific nodes.
  affinity: |
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: {{ template "frontend.name" . }}
                app.kubernetes.io/instance: "{{ .Release.Name }}"
            namespaces:
              - {{ .Release.Namespace | quote }}
            topologyKey: kubernetes.io/hostname
          weight: 1
  # affinity: |
  #   podAntiAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       - labelSelector:
  #           matchLabels:
  #             app.kubernetes.io/name: {{ template "frontend.name" . }}
  #             app.kubernetes.io/instance: "{{ .Release.Name }}"
  #         topologyKey: kubernetes.io/hostname

  # Toleration Settings for server pods
  # This should be either a multi-line string or YAML matching the Toleration array
  # in a PodSpec.
  tolerations: []

  # nodeSelector labels for server pod assignment, formatted as a multi-line string or YAML map.
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  # Example:
  # nodeSelector:
  #   beta.kubernetes.io/arch: amd64
  nodeSelector: {}

#
# Cycloid Console API
#
backend:
  # True if you want to enable the Cycloid Console API.
  enabled: true

  nameOverride: "api"
  fullnameOverride: ""

  # The externally accessible FQDN for the Cycloid Console API.
  # If you change this value, don't to also update the ingress declaration below.
  url: "http://api.cycloid.local"

  replicaCount: 1

  image:
    # If using AWS replace by 661913936052.dkr.ecr.eu-west-1.amazonaws.com/youdeploy-http-api
    repository: rg.fr-par.scw.cloud/cycloidio/cycloid-backend
    pullPolicy: Always
    # Cycloid Console API version to use.
    # Overrides the image tag whose default is the chart appVersion.
    tag: "latest-public"

  # If enabled, split API and Task-manager/Worker (process job in queue) in 2 pods
  taskManager:
    enabled: true
    replicaCount: 1

  # Concourse server to be used by the Cycloid Console API.
  # Defaults to the included one within the chart, but you also use a custom one if needed.
  concourse:
    url: "http://cycloid-concourse-web"
    port: 8080
    team: main
    user: cycloid
    # We recommend changing this default value, but don't forget to update the matching password
    # in the concourse section below.
    password: "##concourse-password##"

  # Vault server to be used by the Cycloid Console API.
  # Defaults to the included one within the chart, but you also use a custom one if needed.
  vault:
    url: "http://cycloid-vault:8200"
    # These value have to be changed as explained in the installation documentation.
    roleId: "##cycloid-vault-approle-role-id##"
    secretId: "##cycloid-vault-approle-secret-id##"

  cryptoSigningKey: "##backend-cryptoSigningKey##"
  jwtKey1: "##backend-jwtKey1##"

  # extraEnvVars is a list of extra environment variables to set.
  extraEnvVars:
    EMAIL_SMTP_SVR_ADDR: "##smtp-host:smtp-port##"
    EMAIL_SMTP_USERNAME: "##smtp-username##"
    EMAIL_SMTP_PASSWORD: "##smtp-password##"
    EMAIL_ADDR_FROM: "Cycloid Console <noreply@domain.tld>"
    EMAIL_ADDR_RETURN_PATH: "admin@domain.tld"
    LOG_LEVEL: "INFO"
    LOG_SVC_LEVEL: "NONE"
    # REDIS_INSECURE_SKIP_TLS: true
    # COST_EXPLORER_ES_INSECURE_SKIP_TLS: true
    # Allow additional Origins to request the API. Multiple Origins can be specified using a comma ','.
    # e.g, CORS_ALLOWED_ORIGINS: "https://domain1.tld,http://domain2.tld"
    # By default, the Frontend URL is already allowed.
    # CORS_ALLOWED_ORIGINS: ""

  # extraSecretEnvVars is a list of extra environment variables to set.
  # These variables take value from existing Secret objects.
  extraSecretEnvVars:
    - envName: REDIS_CA_CERT
      secretName: cycloid-redis-crt
      secretKey: ca.crt

      # - envName: COST_EXPLORER_ES_CA_CERT
      #   secretName: cost-explorer-es-http-certs-public
      #   secretKey: ca.crt

  # extraConfigMapEnvVars is a list of extra environment variables to set.
  # These variables take value from existing ConfigMap objects.
  extraConfigMapEnvVars:
    []
    # - envName: AWS_SECRET_ACCESS_KEY
    #   configMapName: vault
    #   configMapKey: AWS_SECRET_ACCESS_KEY

  # extraFullConfigMapEnvVars is the name of an existing ConfigMap containing extra env vars for containers.
  # All the ConfigMap keys will be accessible as env vars within the containers.
  extraFullConfigMapEnvVars: ""

  # extraFullSecretEnvVars is the name of an existing Secret containing extra env vars for containers.
  # All the Secret keys will be accessible as env vars within the containers.
  extraFullSecretEnvVars: ""

  # volumes is a list of volumes made available to all containers. These are rendered
  # via toYaml rather than pre-processed like the extraVolumes value.
  # The purpose is to make it easy to share volumes between containers.
  volumes: []

  # volumeMounts is a list of volumeMounts for the main server container. These are rendered
  # via toYaml rather than pre-processed like the extraVolumes value.
  # The purpose is to make it easy to share volumes between containers.
  volumeMounts: []

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  podSecurityContext:
    enabled: false
    # fsGroup: 2000

  securityContext:
    enabled: false
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  ingress:
    enabled: true
    className: ""
    annotations:
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "360"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "360"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "360"
      nginx.ingress.kubernetes.io/proxy-body-size: 20m
      # If using the nginx-ingress-controller from NGINXinc: https://github.com/nginxinc/kubernetes-ingress
      # nginx.org/proxy-connect-timeout: "360s"
      # nginx.org/proxy-send-timeout: "360s"
      # nginx.org/proxy-read-timeout: "360s"
    hosts:
      - host: api.cycloid.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: cycloid-local-tls
    #    hosts:
    #      - api.cycloid.local

  resources:
    {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 500m
    #   memory: 256Mi
    # requests:
    #   cpu: 1
    #   memory: 512Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  # Affinity Settings
  # Commenting out or setting as empty the affinity variable, will allow
  # deployment to single node services such as Minikube
  # This should be either a multi-line string or YAML matching the PodSpec's affinity field.
  affinity: |
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: {{ template "backend.name" . }}
                app.kubernetes.io/instance: "{{ .Release.Name }}"
            namespaces:
              - {{ .Release.Namespace | quote }}
            topologyKey: kubernetes.io/hostname
          weight: 1
  # affinity: |
  #   podAntiAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       - labelSelector:
  #           matchLabels:
  #             app.kubernetes.io/name: {{ template "backend.name" . }}
  #             app.kubernetes.io/instance: "{{ .Release.Name }}"
  #         topologyKey: kubernetes.io/hostname

  # Toleration Settings for server pods
  # This should be either a multi-line string or YAML matching the Toleration array
  # in a PodSpec.
  tolerations: []

  # nodeSelector labels for server pod assignment, formatted as a multi-line string or YAML map.
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  # Example:
  # nodeSelector:
  #   beta.kubernetes.io/arch: amd64
  nodeSelector: {}

  cronJob:
    resources:
      {}
      # We usually recommend not to specify cronjob resources and to leave this as a conscious
      # choice for the user. This also increases chances charts run on environments with little
      # resources, such as Minikube. If you do want to specify resources, uncomment the following
      # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      # limits:
      #   cpu: 500m
      #   memory: 256Mi
      # requests:
      #   cpu: 1
      #   memory: 512Mi

    kpiImport:
      enabled: true
      schedule: "0 */1 * * *"

    # Injestion cronJob for Cloud Cost Management
    ccm:
      schedule: "0 0 * * *"

    # Cloud provider price injestion cronJob for Cost Estimation
    costEstimation:
      # Ingest the price of the AWS cloud provider for use in the Cost Estimation feature.
      aws:
        enabled: false
        schedule: "0 0 * * 0"
        args:
          - "/entrypoint"
          - "/go/youdeploy-http-api"
          - "pricing"
          - "ingest"
          - "--config-file=/opt/config.yml"
          - "--pricing-ingest-providers"
          - "aws"
          - "--pricing-ingest-aws-use-known-services"
          - "--pricing-ingest-aws-minimal"

      # Ingest the price of the Azure cloud provider for use in the Cost Estimation feature.
      azure:
        enabled: false
        schedule: "0 0 * * 0"
        args:
          - "/entrypoint"
          - "/go/youdeploy-http-api"
          - "pricing"
          - "ingest"
          - "--config-file=/opt/config.yml"
          - "--pricing-ingest-providers"
          - "azure"
          - "--pricing-ingest-azure-use-known-services"
          - "--pricing-ingest-azure-minimal"

      # Ingest the price of the GCP cloud provider for use in the Cost Estimation feature.
      gcp:
        enabled: false
        schedule: "0 0 * * 0"
        # Please create the following secret to provider PRICING_INGEST_GOOGLE_CREDENTIAL_JSON variable
        # kubectl create secret generic pricing-ingest-google-credential --from-file=gcp-credentials.json
        # Secret name wich container GCP json credential used to reach GCP pricing datas.
        secretName: pricing-ingest-google-credential
        args:
          - "/entrypoint"
          - "/go/youdeploy-http-api"
          - "pricing"
          - "ingest"
          - "--config-file=/opt/config.yml"
          - "--pricing-ingest-providers"
          - "google"
          - "--pricing-ingest-google-project=$(PRICING-INGEST-GOOGLE-PROJECT)"
          - "--pricing-ingest-google-credential-json"
          - "$(PRICING_INGEST_GOOGLE_CREDENTIAL_JSON)"
          - "--pricing-ingest-google-use-known-services"
          - "--pricing-ingest-google-minimal"

#
# MySQL
#
# Configuration values for the mysql dependency.
# Ref: https://github.com/bitnami/charts/tree/master/bitnami/mysql
#
mysql:
  ## Use the MySQL chart dependency.
  ##
  ## Set to false if bringing your own MySQL, and set the corresponding `secrets`
  ## fields that correspond to the PostgreSQL variables that `concourse web` should use
  ## to connect to.
  ##
  enabled: true

  nameOverride: "mysql"

  # Use the default MySQL image from mysql charts
  #
  # image:
  #   registry: docker.io
  #   repository: bitnami/mysql
  #   tag: 8.4.3

  ## MySQL Authentication parameters
  ## @param mysql.auth.rootPassword MySQL root password
  ## @param mysql.auth.database MySQL custom database
  ## @param mysql.auth.username MySQL custom user name
  ## @param mysql.auth.password MySQL custom user password
  ## ref: https://github.com/bitnami/bitnami-docker-mysql#setting-the-root-password-on-first-run
  ##      https://github.com/bitnami/bitnami-docker-mysql/blob/master/README.md#creating-a-database-on-first-run
  ##      https://github.com/bitnami/bitnami-docker-mysql/blob/master/README.md#creating-a-database-user-on-first-run
  auth:
    rootPassword: "##mysql-auth-rootPassword##"
    database: cycloid
    username: cycloid
    password: "##mysql-auth-password##"

  ## @param architecture MySQL architecture (`standalone` or `replication`)
  ##
  #architecture: standalone

  ## MySQL Primary configuration
  ##
  primary:
    # MySQL Primary Persistence parameters
    # ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
    # Used to provide storage that persists beyond the lifecycle of individual pods.
    # A Persistent Volume retains data even if the pod is removed.
    # @param mysql.primary.persistence.enabled Enable persistence on MySQL using PVC(s)
    # @param mysql.primary.persistence.storageClass Persistent Volume storage class. This Should be specified if no default StorageClass defined in your cluster.
    # @param mysql.primary.persistence.accessModes [array] Persistent Volume access modes
    # @param mysql.primary.persistence.size Persistent Volume size
    #
    persistence:
      enabled: true
      storageClass: ""
      accessModes:
        - ReadWriteOnce
      size: 8Gi

    # Disable binlog by default
    #TODO
    #extraFlags: "--disable-log-bin"

#
# External MySQL Configuration
# All of these values are only used if `mysql.enabled=false`
#
externalMysql:
  # External MySQL server host
  host: localhost
  # External MySQL server port
  port: 3306
  # External MySQL username
  user: cycloid
  # External MySQL user password
  password: ""
  #External MySQL database name
  database: cycloid
  #The name of an existing secret with database credentials
  # NOTE: Must contain key `mysql-password`
  # NOTE: When it's set, the `externalMysql.password` parameter is ignored
  existingSecret: ""

#
# Redis
#
redis:
  ## Use the Redis chart dependency.
  ##
  ## Set to false if bringing your own MySQL, and set the corresponding `secrets`
  ## fields that correspond to the PostgreSQL variables that `concourse web` should use
  ## to connect to.
  ##
  enabled: true
  nameOverride: "redis"

  # image:
  #   registry: docker.io
  #   repository: cycloid/redis
  #   tag: 8.2.0
  #   pullPolicy: IfNotPresent

  ## Redis Authentication parameters
  auth:
    ## @param auth.enabled Enable password authentication
    enabled: true
    ## @param auth.password Redis password
    ## Defaults to a random 10-character alphanumeric string if not set
    ##
    password: "##redis-auth-password##"
  tls:
    enabled: true
    autoGenerated: true

  master:
    persistence:
      enabled: true
      storageClass: ""
      accessModes:
        - ReadWriteOnce
      size: 8Gi

    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 256Mi

#
# External Redis Configuration
# All of these values are only used if `redis.enabled=false`
#
externalRedis:
  #External Redis server host
  host: localhost
  #External Redis server port
  port: 6379
  #External Redis server database
  database: "0"
  #External Redis password
  password: ""
  #Enable user authentification
  auth:
    enabled: false
    username: "default"
    password: ""
  # If enabled, use rediss schema
  tls:
    enabled: false

#
# External Elasticsearch Configuration
#
externalElasticsearch:
  # for now, the externalElasticsearch config will be at first
  # the only solution to configure the backend for Cloud Cost Management
  enabled: false
  #External ES server protocol
  scheme: https
  #External ES server host
  host: cost-explorer-es-http
  #External ES server port
  port: 9200
  #External ES server database
  username: elastic
  #External ES password
  password: ""
  #The name of an existing secret with database credentials
  # NOTE: Must contain key `elasticsearch-password` by default is not overriden with `existingSecretKey`
  # NOTE: When it's set, the `externalElasticsearch.password` parameter is ignored
  existingSecret: ""
  #existingSecretKey: elastic

#
# Concourse
#
# Configuration values for the concourse dependency.
# Ref: https://github.com/concourse/concourse-chart
#
concourse:
  ## Use the Concourse chart dependency.
  ##
  ## Set to false if bringing your own MySQL, and set the corresponding `secrets`
  ## fields that correspond to the PostgreSQL variables that `concourse web` should use
  ## to connect to.
  ##
  enabled: true

  fullnameOverride: cycloid-concourse

  imageTag: "7.9.1"

  ## Configuration values for the Concourse application (worker and web components).
  ## The values specified here are almost direct references to the flags under the
  ## `concourse web` and `concourse worker` commands.
  ##
  concourse:
    ## Configurations for the `web` component based on the possible flags configurable
    ## through the `concourse web` command.
    ##
    web:
      ## A name for this Concourse cluster, to be displayed on the dashboard page.
      ##
      clusterName: cycloid
      ## Enable equivalent resources across pipelines and teams to share a single version history.
      ## Ref: https://concourse-ci.org/global-resources.html
      ##
      enableGlobalResources: false
      ## Enable automatic rerunning of builds when worker disappears
      ##
      enableBuildRerunWhenWorkerDisappears: true
      ## URL used to reach any ATC from the outside world.
      ## This is *very* important for a proper authentication workflow as
      ## browser redirects are based on the value set here.
      ##
      ## Example: http://ci.concourse-ci.org
      ##
      externalUrl: http://concourse.cycloid.local

      # Disable the use of Kubernetes Secrets as the credential provider for concourse pipelines (true by default).
      kubernetes:
        enabled: false

      # Configuration for using Vault as a credential manager.
      ## Ref: https://concourse-ci.org/creds.html#vault
      ##
      vault:
        ## Enable the use of Vault as a credential manager.
        ##
        enabled: true

        ## URL pointing to vault addr (i.e. http://vault:8200).
        ##
        url: http://cycloid-vault:8200

        ## Vault path under which to namespace credentials lookup.
        ##
        pathPrefix: /cycloid

        ## Vault authentication backend, leave this blank if using an initial periodic token.
        ## Currently supported backends: token, approle, cert.
        ##
        authBackend: "approle"

        ## if the Vault authentication backend requires params from secrets, set this to true,
        ## and provide a value in secrets (field `vault-client-auth-param`).
        ##
        useAuthParam: true

      auth:
        mainTeam:
          ## Comma-separated list of local Concourse users to be included as members of the `main` team.
          ## Make sure you have local users support enabled (`concourse.web.localAuth.enabled`) and
          ## that the users were added (`secrets.localUsers`).
          ##
          localUser: "cycloid"

      ## Configurations regarding how the web component is able to connect to a postgres
      ## instance.
      ##
      postgres:
        ## The host to connect to. Need to be specified if bringing your own PostgreSQL.
        ##
        host:
        ## The port to connect to.
        ##
        port: 5432
        ## The name of the database to use.
        ##
        database: atc
        ## user/password defined under secrets section

    worker:
      baggageclaim:
        driver: overlay

  web:
    ## Enable or disable the web component.
    ## This allows the creation of worker-only releases by setting this to false.
    ##
    enabled: true
    ## Number of replicas.
    ##
    replicas: 1

    ## Array of extra containers to run alongside the Concourse Web
    ## container.
    ##
    ## Example:
    ## - name: myapp-container
    ##   image: busybox
    ##   command: ['sh', '-c', 'echo Hello && sleep 3600']
    ##
    sidecarContainers:
      - name: concourse-team-authorized-key-sync
        image: cycloid/concourse-team-authorized-key-sync:latest
        imagePullPolicy: Always
        env:
          - name: VAULT_URL
            value: http://cycloid-vault:8200
          - name: VAULT_ROLE_ID
            value: "##cycloid-ro-vault-approle-role-id##"
          - name: VAULT_SECRET_ID
            value: "##cycloid-ro-vault-approle-secret-id##"
          - name: YAML_KEYS_FILE
            value: /etc/concourse-teams/tsa-team-authorized-keys.yaml
          - name: VERBOSE
            value: "True"
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
          - mountPath: /etc/concourse-teams
            name: concourse-teams

    ## Array of extra initContainers to run alongside the Concourse Web
    ## container.
    ##
    ## Example:
    ## - name: myapp-init-container
    ##   image: busybox
    ##   command: ['sh', '-c', 'echo Hello && sleep 3600']
    ##
    extraInitContainers:
      - name: concourse-team-authorized-key-init
        image: busybox
        env:
          - name: YAML_KEYS_FILE
            value: /etc/concourse-teams/tsa-team-authorized-keys.yaml
        command:
          - /bin/sh
          - -c
          - |
            touch $YAML_KEYS_FILE;
        volumeMounts:
          - mountPath: /etc/concourse-teams
            name: concourse-teams

    ## Enable or disable the process namespace sharing for the web nodes.
    ## This allows signaling the concourse process from a sidecar container.
    ## eg.: signal concourse web to reload the team authorized keys file.
    ##
    ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/
    ##
    shareProcessNamespace: true

    ## Configure resource requests and limits.
    ## Ref: https://kubernetes.io/docs/user-guide/compute-resources/
    ##
    resources:
      requests:
        cpu: "100m"
        memory: "1Gi"
      limits:
        cpu: "1000m"
        memory: "1.5Gi"

    ## Configure additional environment variables for the
    ## web containers.
    ## Example:
    ##
    ##   - name: CONCOURSE_LOG_LEVEL
    ##     value: "debug"
    ##   - name: CONCOURSE_TSA_LOG_LEVEL
    ##     value: "debug"
    ##
    env:
      - name: CONCOURSE_TSA_TEAM_AUTHORIZED_KEYS_FILE
        value: /etc/concourse-teams/tsa-team-authorized-keys.yaml

    ## Configure additional volumes for the
    ## web container(s).
    ##
    ## Example:
    ##
    ##   - name: my-team-authorized-keys
    ##     configMap:
    ##       name: my-team-authorized-keys-config
    ##
    ## Ref: https://kubernetes.io/docs/concepts/storage/volumes/
    ##
    additionalVolumes:
      - name: concourse-teams
        emptyDir: {}

    ## Configure additional volumeMounts for the
    ## web container(s)
    ##
    ## Example:
    ##
    ##  - name: my-team-authorized-keys
    ##    mountPath: /my-team-authorized-keys
    ##
    ## Ref: https://kubernetes.io/docs/concepts/storage/volumes/
    ##
    additionalVolumeMounts:
      - name: concourse-teams
        mountPath: /etc/concourse-teams

    ## Ingress configuration.
    ## Ref: https://kubernetes.io/docs/user-guide/ingress/
    ##
    ingress:
      ## Enable Ingress.
      ##
      enabled: false

      ## Annotations to be added to the web ingress.
      ## Example:
      ##   kubernetes.io/tls-acme: 'true'
      ##
      annotations: {}

      ## Hostnames.
      ## Must be provided if Ingress is enabled.
      ## Example:
      ##   - concourse.domain.com
      ##
      hosts:
        - concourse.cycloid.local

      ## TLS configuration.
      ## Secrets must be manually created in the namespace.
      ## Example:
      ##   - secretName: concourse-web-tls
      ##     hosts:
      ##       - concourse.domain.com
      ##
      tls:
        []
        #  - secretName: cycloid-local-tls
        #    hosts:
        #      - concourse.cycloid.local

  ## Configuration values for Concourse Worker components.
  ## For more information regarding the characteristics of
  ## Concourse Workers, see https://concourse-ci.org/concourse-worker.html
  ##
  worker:
    ## Enable or disable the worker component.
    ## This can allow users to create web only releases by setting this to false
    ##
    enabled: false

    ## Number of replicas.
    ##
    replicas: 1

    ## Configure resource requests and limits.
    ## Ref: https://kubernetes.io/docs/user-guide/compute-resources/
    ##
    resources:
      requests:
        cpu: "1"
        memory: "512Mi"
      limits:
        memory: "1Gi"

    ## Node selector for the worker nodes.
    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
    ##
    nodeSelector: {}

  ## Persistent Volume Storage configuration.
  ## Ref: https://kubernetes.io/docs/user-guide/persistent-volumes
  ##
  persistence:
    ## Enable persistence using Persistent Volume Claims.
    ## Ignored for Kind: Deployment. If persistence is needed use kind: StatefulSet
    ##
    enabled: true

    ## Worker Persistence configuration.
    ##
    worker:
      ## concourse data Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      storageClass:

      ## Persistent Volume Access Mode.
      ##
      accessMode: ReadWriteOnce

      ## Persistent Volume Storage Size.
      ##
      size: 80Gi

  postgresql:
    ## Use the PostgreSQL chart dependency.
    ##
    ## Set to false if bringing your own PostgreSQL, and set the corresponding `secrets`
    ## fields that correspond to the PostgreSQL variables that `concourse web` should use
    ## to connect to.
    ##
    enabled: true

    fullnameOverride: cycloid-concourse-postgresql

    primary:
      resourcesPreset: "micro"

    auth:
      ### PostgreSQL User to create.
      username: concourse
      ## PostgreSQL Password for the new user.
      ## If not set, a random 10 characters password will be used.
      ##
      password: "##concourse-postgresql-auth-password##"
      # Password for the "postgres" admin user
      postgresPassword: "##concourse-postgresql-auth-postgresPassword##"
      ## PostgreSQL Database to create.
      ##
      database: atc

    ## Persistent Volume Storage configuration for PostgreSQL.
    ##
    ## Ref: https://kubernetes.io/docs/user-guide/persistent-volumes
    ##
    persistence:
      ## Enable PostgreSQL persistence using Persistent Volume Claims.
      ##
      enabled: true
      ## Persistent Volume Storage Class to be used by PersistentVolumes created
      ## for PostgreSQL.
      ##
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      storageClass:
      ## Persistent Volume Access Mode.
      ##
      accessModes:
        - ReadWriteOnce
      ## Persistent Volume Storage Size.
      ##
      size: 8Gi

  secrets:
    ## User/Pass need to be specified if bringing your own PostgreSQL.
    postgresUser:
    postgresPassword: ""

    ## List of `username:password` or `username:bcrypted_password` combinations for all your local concourse users.
    ## For details of expected format, see https://concourse-ci.org/local-auth.html
    ##
    localUsers: "cycloid:##concourse-password##"

    ## Concourse Host Keys.
    ## Ref: https://concourse-ci.org/install.html#generating-keys
    ##
    hostKey: |-
      ##concourse-secrets-hostKey##

    hostKeyPub: |-
      ##concourse-secrets-hostKeyPub##

    ## Concourse Session Signing Keys.
    ## Ref: https://concourse-ci.org/concourse-generate-key.html
    ##
    sessionSigningKey: |-
      ##concourse-secrets-sessionSigningKey##

    ## Concourse Worker Keys.
    ## Ref: https://concourse-ci.org/concourse-generate-key.html
    ##
    workerKey: |-
      ##concourse-secrets-workerKey##

    workerKeyPub: |-
      ##concourse-secrets-workerKeyPub##

    ## vault authentication parameters
    ## Parameter to pass when logging in via the backend
    ## Required for "approle" authenication method
    ## e.g. "role_id:x,secret_id:x"
    ## Ref: https://concourse-ci.org/vault-credential-manager.html#vault-approle-auth
    ##
    vaultAuthParam: "role_id:##cycloid-ro-vault-approle-role-id##,secret_id:##cycloid-ro-vault-approle-secret-id##"

#
# Vault
#
# Configuration values for the vault dependency.
# Ref: https://github.com/hashicorp/vault-helm
#
vault:
  # Use the Vault chart dependency.
  enabled: true

  injector:
    enabled: false

    leaderElector:
      enabled: false

  server:
    # image:
    #   tag: "1.15.2"

    # This can be useful when you want your services running on a Kubernetes
    # cluster to self-authenticate against Vault without the need to pass around Vault credentials.
    authDelegator:
      enabled: false

    # This configures the Vault Statefulset to create a PVC for data
    # storage when using the file or raft backend storage engines.
    # See https://www.vaultproject.io/docs/configuration/storage/index.html to know more
    dataStorage:
      enabled: true
      size: 10Gi
      # Location where the PVC will be mounted.
      mountPath: "/vault/data"
      # Name of the storage class to use.  If null it will use the
      # configured default Storage Class.
      storageClass: null
      # Access Mode of the storage device being used for the PVC
      accessMode: ReadWriteOnce
      # Annotations to apply to the PVC
      annotations: {}

    # Run Vault in "standalone" mode. This is the default mode that will deploy if
    # no arguments are given to helm. This requires a PVC for data storage to use
    # the "file" backend.  This mode is not highly available and should not be scaled
    # past a single replica.
    standalone:
      # config is a raw string of default configuration when using a Stateful
      # deployment. Default is to use a PersistentVolumeClaim mounted at /vault/data
      # and store data there. This is only used when using a Replica count of 1, and
      # using a stateful set. This should be HCL.

      # Note: Configuration files are stored in ConfigMaps so sensitive data
      # such as passwords should be either mounted through extraSecretEnvironmentVars
      # or through a Kube secret.  For more information see:
      # https://www.vaultproject.io/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations
      config: |
        ui = true
        listener "tcp" {
          tls_disable = 1
          address = "[::]:8200"
          cluster_address = "[::]:8201"
        }
        storage "file" {
          path = "/vault/data"
        }

    resources: {}
    # resources:
    #   requests:
    #     memory: 256Mi
    #     cpu: 250m
    #   limits:
    #     memory: 256Mi
    #     cpu: 250m

    # Ingress allows ingress services to be created to allow external access
    # from Kubernetes to access Vault pods.
    ingress:
      enabled: false
      labels:
        {}
        # traffic: external
      annotations:
        {}
        # |
        # kubernetes.io/ingress.class: nginx
        # kubernetes.io/tls-acme: "true"
        #   or
        # kubernetes.io/ingress.class: nginx
        # kubernetes.io/tls-acme: "true"

      # When HA mode is enabled and K8s service registration is being used,
      # configure the ingress to point to the Vault active service.
      activeService: true
      hosts:
        - host: vault.cycloid.local
          paths: []
      tls: []
      #  - secretName: cycloid-local-tls
      #    hosts:
      #      - vault.cycloid.local
